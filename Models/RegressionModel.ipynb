{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model\n",
    "\n",
    "In this notebook we will build a simple multiple regression model which will be used as a baseline model for the comparision with the xGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Packages \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Data with Features \n",
    "data_hedonic = pd.read_csv ('/Users/paulahofmann/Documents/Coding/Online-Review/FeaturePreperation/Data_with_Features/Final Data/Hedonic_Final.csv')\n",
    "data_utilitarian = pd.read_csv ('/Users/paulahofmann/Documents/Coding/Online-Review/FeaturePreperation/Data_with_Features/Final Data/Utilitarian_Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary for sentiment transformation\n",
    "sentiment_mapping = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "\n",
    "# Using map function to create a new column 'sentiment_c' with transformed values\n",
    "data_hedonic['sentiment_c'] = data_hedonic['Sentiment_Classification'].map(sentiment_mapping)\n",
    "data_utilitarian['sentiment_c'] = data_hedonic['Sentiment_Classification'].map(sentiment_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_helpful_votes(df):\n",
    "    for product_id, group in df.groupby('product'):\n",
    "        total_helpful_votes = group['helpful_vote'].sum()\n",
    "        df.loc[group.index, 'total_helpful_votes'] = total_helpful_votes\n",
    "        df.loc[group.index, 'helpful_ratio'] = group['helpful_vote'] / total_helpful_votes\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will simply sort all reviews that have at least one helpful Vote\n",
    "data_utilitarian_helpful = data_utilitarian[data_utilitarian['helpful_vote'] > 0]\n",
    "data_hedonic_helpful = data_hedonic[data_hedonic['helpful_vote'] > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join dataframes\n",
    "data_helpful = pd.concat([data_utilitarian_helpful, data_hedonic_helpful])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Define features and target\n",
    "features = ['rating', 'sentiment_c', 'subjective_score', 'elap_days', 'image', 'ver_purch', 'word_count',\n",
    "            'sent_count', 'sent_length', 'title_length', '#adj', '#adv', '#nouns', 'FRE']\n",
    "target = 'helpful_ratio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.00010170414264582919\n",
      "             Feature  Coefficient\n",
      "0             rating    -0.000094\n",
      "1        sentiment_c    -0.000465\n",
      "2   subjective_score     0.001349\n",
      "3          elap_days     0.002502\n",
      "4              image     0.002357\n",
      "5          ver_purch     0.001062\n",
      "6         word_count     0.003780\n",
      "7         sent_count    -0.000351\n",
      "8        sent_length     0.001807\n",
      "9       title_length    -0.000185\n",
      "10              #adj     0.000280\n",
      "11              #adv     0.000547\n",
      "12            #nouns     0.001368\n",
      "13               FRE     0.001603\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          helpful_ratio   R-squared:                       0.039\n",
      "Model:                            OLS   Adj. R-squared:                  0.015\n",
      "Method:                 Least Squares   F-statistic:                     1.643\n",
      "Date:                Fri, 24 May 2024   Prob (F-statistic):             0.0638\n",
      "Time:                        16:02:43   Log-Likelihood:                 1293.3\n",
      "No. Observations:                 587   AIC:                            -2557.\n",
      "Df Residuals:                     572   BIC:                            -2491.\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0061      0.001      5.447      0.000       0.004       0.008\n",
      "x1         -9.367e-05      0.001     -0.064      0.949      -0.003       0.003\n",
      "x2            -0.0005      0.001     -0.317      0.751      -0.003       0.002\n",
      "x3             0.0013      0.001      1.174      0.241      -0.001       0.004\n",
      "x4             0.0025      0.001      2.170      0.030       0.000       0.005\n",
      "x5             0.0024      0.001      2.099      0.036       0.000       0.005\n",
      "x6             0.0011      0.001      0.928      0.354      -0.001       0.003\n",
      "x7             0.0038      0.003      1.235      0.217      -0.002       0.010\n",
      "x8            -0.0004      0.003     -0.125      0.901      -0.006       0.005\n",
      "x9             0.0018      0.002      0.977      0.329      -0.002       0.005\n",
      "x10           -0.0002      0.001     -0.163      0.870      -0.002       0.002\n",
      "x11            0.0003      0.001      0.240      0.811      -0.002       0.003\n",
      "x12            0.0005      0.001      0.464      0.643      -0.002       0.003\n",
      "x13            0.0014      0.001      1.128      0.260      -0.001       0.004\n",
      "x14            0.0016      0.002      0.956      0.340      -0.002       0.005\n",
      "==============================================================================\n",
      "Omnibus:                      960.040   Durbin-Watson:                   2.029\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           331011.784\n",
      "Skew:                           9.812   Prob(JB):                         0.00\n",
      "Kurtosis:                     117.667   Cond. No.                         5.66\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Significant features based on p-values:\n",
      "Index(['x4', 'x5'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split data into training and testing sets\n",
    "X = data_utilitarian_helpful[features]\n",
    "y = data_utilitarian_helpful[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define and fit the model using sklearn\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Interpret the results\n",
    "coefficients = pd.DataFrame({'Feature': features, 'Coefficient': model.coef_})\n",
    "print(coefficients)\n",
    "\n",
    "# Add a constant to the features matrix for the intercept term\n",
    "X_train_const = sm.add_constant(X_train_scaled)\n",
    "\n",
    "# Fit the linear regression model using statsmodels\n",
    "sm_model = sm.OLS(y_train, X_train_const)\n",
    "results = sm_model.fit()\n",
    "\n",
    "# Get the summary of the regression results\n",
    "print(results.summary())\n",
    "\n",
    "# Extract p-values and identify significant features\n",
    "p_values = results.pvalues\n",
    "significant_features = p_values[p_values < 0.05].index\n",
    "significant_features = significant_features[significant_features != 'const']  # Exclude the intercept\n",
    "print(\"\\nSignificant features based on p-values:\")\n",
    "print(significant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.00012498544500094545\n",
      "             Feature  Coefficient\n",
      "0             rating    -0.000871\n",
      "1        sentiment_c     0.000582\n",
      "2   subjective_score    -0.000310\n",
      "3          elap_days     0.000417\n",
      "4              image     0.001395\n",
      "5          ver_purch     0.000803\n",
      "6         word_count     0.001552\n",
      "7         sent_count    -0.000294\n",
      "8        sent_length     0.000692\n",
      "9       title_length     0.000580\n",
      "10              #adj    -0.000584\n",
      "11              #adv    -0.000503\n",
      "12            #nouns    -0.000629\n",
      "13               FRE    -0.000266\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          helpful_ratio   R-squared:                       0.041\n",
      "Model:                            OLS   Adj. R-squared:                  0.023\n",
      "Method:                 Least Squares   F-statistic:                     2.224\n",
      "Date:                Fri, 24 May 2024   Prob (F-statistic):            0.00602\n",
      "Time:                        16:03:52   Log-Likelihood:                 2170.4\n",
      "No. Observations:                 744   AIC:                            -4311.\n",
      "Df Residuals:                     729   BIC:                            -4242.\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0047      0.000      9.715      0.000       0.004       0.006\n",
      "x1            -0.0009      0.001     -1.116      0.265      -0.002       0.001\n",
      "x2             0.0006      0.001      0.745      0.456      -0.001       0.002\n",
      "x3            -0.0003      0.001     -0.603      0.546      -0.001       0.001\n",
      "x4             0.0004      0.000      0.846      0.398      -0.001       0.001\n",
      "x5             0.0014      0.000      2.851      0.004       0.000       0.002\n",
      "x6             0.0008      0.000      1.624      0.105      -0.000       0.002\n",
      "x7             0.0016      0.001      1.041      0.298      -0.001       0.004\n",
      "x8            -0.0003      0.001     -0.201      0.841      -0.003       0.003\n",
      "x9             0.0007      0.001      0.925      0.355      -0.001       0.002\n",
      "x10            0.0006      0.000      1.178      0.239      -0.000       0.002\n",
      "x11           -0.0006      0.001     -1.159      0.247      -0.002       0.000\n",
      "x12           -0.0005      0.001     -0.942      0.347      -0.002       0.001\n",
      "x13           -0.0006      0.001     -1.151      0.250      -0.002       0.000\n",
      "x14           -0.0003      0.001     -0.414      0.679      -0.002       0.001\n",
      "==============================================================================\n",
      "Omnibus:                      895.271   Durbin-Watson:                   2.066\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            75078.328\n",
      "Skew:                           6.066   Prob(JB):                         0.00\n",
      "Kurtosis:                      50.694   Cond. No.                         6.28\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Significant features based on p-values:\n",
      "Index(['x5'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X = data_hedonic_helpful[features]\n",
    "y = data_hedonic_helpful[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define and fit the model using sklearn\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Interpret the results\n",
    "coefficients = pd.DataFrame({'Feature': features, 'Coefficient': model.coef_})\n",
    "print(coefficients)\n",
    "\n",
    "# Add a constant to the features matrix for the intercept term\n",
    "X_train_const = sm.add_constant(X_train_scaled)\n",
    "\n",
    "# Fit the linear regression model using statsmodels\n",
    "sm_model = sm.OLS(y_train, X_train_const)\n",
    "results = sm_model.fit()\n",
    "\n",
    "# Get the summary of the regression results\n",
    "print(results.summary())\n",
    "\n",
    "# Extract p-values and identify significant features\n",
    "p_values = results.pvalues\n",
    "significant_features = p_values[p_values < 0.05].index\n",
    "significant_features = significant_features[significant_features != 'const']  # Exclude the intercept\n",
    "print(\"\\nSignificant features based on p-values:\")\n",
    "print(significant_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model on Product level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.311634556441197e-05\n",
      "             Feature  Coefficient\n",
      "0             rating    -0.001144\n",
      "1        sentiment_c     0.000976\n",
      "2   subjective_score    -0.000212\n",
      "3          elap_days     0.000419\n",
      "4              image     0.000896\n",
      "5          ver_purch     0.000194\n",
      "6         word_count     0.000379\n",
      "7         sent_count    -0.000108\n",
      "8        sent_length     0.000271\n",
      "9       title_length    -0.000067\n",
      "10              #adj    -0.000046\n",
      "11              #adv    -0.000016\n",
      "12            #nouns     0.000069\n",
      "13               FRE     0.000007\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          helpful_ratio   R-squared:                       0.063\n",
      "Model:                            OLS   Adj. R-squared:                  0.049\n",
      "Method:                 Least Squares   F-statistic:                     4.720\n",
      "Date:                Fri, 24 May 2024   Prob (F-statistic):           2.00e-08\n",
      "Time:                        15:39:24   Log-Likelihood:                 3836.3\n",
      "No. Observations:                1002   AIC:                            -7643.\n",
      "Df Residuals:                     987   BIC:                            -7569.\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0008      0.000      4.703      0.000       0.000       0.001\n",
      "x1            -0.0011      0.000     -4.223      0.000      -0.002      -0.001\n",
      "x2             0.0010      0.000      3.600      0.000       0.000       0.002\n",
      "x3            -0.0002      0.000     -1.132      0.258      -0.001       0.000\n",
      "x4             0.0004      0.000      2.451      0.014    8.34e-05       0.001\n",
      "x5             0.0009      0.000      5.211      0.000       0.001       0.001\n",
      "x6             0.0002      0.000      1.141      0.254      -0.000       0.001\n",
      "x7             0.0004      0.000      0.806      0.421      -0.001       0.001\n",
      "x8            -0.0001      0.000     -0.244      0.808      -0.001       0.001\n",
      "x9             0.0003      0.000      1.087      0.277      -0.000       0.001\n",
      "x10        -6.723e-05      0.000     -0.396      0.692      -0.000       0.000\n",
      "x11        -4.571e-05      0.000     -0.255      0.799      -0.000       0.000\n",
      "x12        -1.572e-05      0.000     -0.087      0.931      -0.000       0.000\n",
      "x13         6.902e-05      0.000      0.385      0.700      -0.000       0.000\n",
      "x14         7.403e-06      0.000      0.036      0.972      -0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                     2063.516   Durbin-Watson:                   1.958\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4701967.885\n",
      "Skew:                          16.142   Prob(JB):                         0.00\n",
      "Kurtosis:                     337.035   Cond. No.                         5.87\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Significant features based on p-values:\n",
      "Index(['x1', 'x2', 'x4', 'x5'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Filter data to only include reviews with at least one helpful vote\n",
    "perfume_data_hedonic = data_hedonic_helpful[data_hedonic_helpful['product'] == 'Facial Spray']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X = perfume_data_hedonic[features]\n",
    "y = perfume_data_hedonic[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define and fit the model using sklearn\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Interpret the results\n",
    "coefficients = pd.DataFrame({'Feature': features, 'Coefficient': model.coef_})\n",
    "print(coefficients)\n",
    "\n",
    "# Add a constant to the features matrix for the intercept term\n",
    "X_train_const = sm.add_constant(X_train_scaled)\n",
    "\n",
    "# Fit the linear regression model using statsmodels\n",
    "sm_model = sm.OLS(y_train, X_train_const)\n",
    "results = sm_model.fit()\n",
    "\n",
    "# Get the summary of the regression results\n",
    "print(results.summary())\n",
    "\n",
    "# Extract p-values and identify significant features\n",
    "p_values = results.pvalues\n",
    "significant_features = p_values[p_values < 0.05].index\n",
    "significant_features = significant_features[significant_features != 'const']  # Exclude the intercept\n",
    "print(\"\\nSignificant features based on p-values:\")\n",
    "print(significant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data to only include reviews with at least one helpful vote\n",
    "utilitarian_battery = data_utilitarian_helpful[data_utilitarian_helpful['product'] == 'Battery']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X = utilitarian_battery[features]\n",
    "y = utilitarian_battery[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define and fit the model using sklearn\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Interpret the results\n",
    "coefficients = pd.DataFrame({'Feature': features, 'Coefficient': model.coef_})\n",
    "print(coefficients)\n",
    "\n",
    "# Add a constant to the features matrix for the intercept term\n",
    "X_train_const = sm.add_constant(X_train_scaled)\n",
    "\n",
    "# Fit the linear regression model using statsmodels\n",
    "sm_model = sm.OLS(y_train, X_train_const)\n",
    "results = sm_model.fit()\n",
    "\n",
    "# Get the summary of the regression results\n",
    "print(results.summary())\n",
    "\n",
    "# Extract p-values and identify significant features\n",
    "p_values = results.pvalues\n",
    "significant_features = p_values[p_values < 0.05].index\n",
    "significant_features = significant_features[significant_features != 'const']  # Exclude the intercept\n",
    "print(\"\\nSignificant features based on p-values:\")\n",
    "print(significant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a DataFrame to collect the results\n",
    "results_df = pd.DataFrame(columns=['main_category', 'feature', 'coefficient', 'p_value', 'significant', 'MSE'])\n",
    "\n",
    "# Perform regression separately for each main category\n",
    "for category in data_utilitarian_helpful['main_category'].unique():\n",
    "    category_data = data_utilitarian_helpful[data_utilitarian_helpful['main_category'] == category]\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X = category_data[features]\n",
    "    y = category_data[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Add a constant to the features matrix for the intercept term\n",
    "    X_train_const = sm.add_constant(X_train_scaled)\n",
    "\n",
    "    # Fit the linear regression model using statsmodels\n",
    "    sm_model = sm.OLS(y_train, X_train_const)\n",
    "    results = sm_model.fit()\n",
    "\n",
    "    # Calculate Mean Squared Error (MSE)\n",
    "    y_pred = results.predict(sm.add_constant(X_test_scaled))\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Collect the results\n",
    "    results_df = pd.concat([\n",
    "        results_df,\n",
    "        pd.DataFrame({\n",
    "            'main_category': category,\n",
    "            'feature': ['const'] + features,\n",
    "            'coefficient': results.params,\n",
    "            'p_value': results.pvalues,\n",
    "            'significant': results.pvalues < 0.05,\n",
    "            'MSE': mse\n",
    "        })\n",
    "    ])\n",
    "\n",
    "# Display the results\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
