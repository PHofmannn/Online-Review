{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "# Importing Packages and Libraries\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "file_path1 = '/Users/paulahofmann/Documents/Coding/Online-Review/FeaturePreperation/Data_with_Features/Final Data/Hedonic_Final.csv'\n",
    "df = pd.read_csv(file_path1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['title_x', 'text', 'images', 'asin', 'parent_asin', 'user_id',\n",
    "       'timestamp', 'verified_purchase', 'text_cleaned',\n",
    "       'text_cleaned1','main_category','features','neutral_score','day_of_week',]\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary for sentiment transformation\n",
    "sentiment_mapping = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "\n",
    "# Using map function to create a new column 'sentiment_c' with transformed values\n",
    "df['sentiment_c'] = df['Sentiment_Classification'].map(sentiment_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'helpful' based on the condition\n",
    "df['helpful'] = (df['helpful_vote'] > 0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "features = ['rating', 'sentiment_c','word_count', 'sent_count', 'sent_length', 'title_length', 'elap_days',\n",
    "       'image', 'ver_purch','FRE','#nouns','#adj', '#adv', 'subjective_score','product']\n",
    "target = 'helpful'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Assuming df is your DataFrame and features & target are defined appropriately\n",
    "# Example:\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Create dummy variables for 'product' column\n",
    "#product_dummies = pd.get_dummies(df['product'], drop_first=True,dtype=int)\n",
    "\n",
    "# Define numerical features and the target\n",
    "numerical_features = ['rating', 'sentiment_c', 'word_count', 'sent_count', 'sent_length', 'title_length', 'elap_days', 'image', 'ver_purch', 'FRE', '#nouns', '#adj', '#adv', 'subjective_score']\n",
    "target = 'helpful'\n",
    "\n",
    "# Concatenate numerical features and dummy variables\n",
    "#X = pd.concat([df[numerical_features], product_dummies], axis=1)\n",
    "X = df [numerical_features]\n",
    "y = df[target]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.398471\n",
      "         Iterations 7\n",
      "                         Results: Logit\n",
      "=================================================================\n",
      "Model:              Logit            Method:           MLE       \n",
      "Dependent Variable: helpful          Pseudo R-squared: 0.120     \n",
      "Date:               2024-05-28 19:00 AIC:              17728.8570\n",
      "No. Observations:   22211            BIC:              17840.9738\n",
      "Df Model:           13               Log-Likelihood:   -8850.4   \n",
      "Df Residuals:       22197            LL-Null:          -10057.   \n",
      "Converged:          1.0000           LLR p-value:      0.0000    \n",
      "No. Iterations:     7.0000           Scale:            1.0000    \n",
      "-----------------------------------------------------------------\n",
      "                  Coef.  Std.Err.    z     P>|z|   [0.025  0.975]\n",
      "-----------------------------------------------------------------\n",
      "rating           -0.3167   0.0197 -16.0821 0.0000 -0.3553 -0.2781\n",
      "sentiment_c       0.0551   0.0361   1.5245 0.1274 -0.0157  0.1260\n",
      "word_count        0.0050   0.0014   3.6450 0.0003  0.0023  0.0077\n",
      "sent_count        0.1853   0.0197   9.3907 0.0000  0.1466  0.2239\n",
      "sent_length       0.0149   0.0030   5.0394 0.0000  0.0091  0.0207\n",
      "title_length     -0.0591   0.0117  -5.0605 0.0000 -0.0820 -0.0362\n",
      "elap_days         0.0001   0.0000   4.1480 0.0000  0.0000  0.0001\n",
      "image             0.8024   0.0823   9.7483 0.0000  0.6411  0.9638\n",
      "ver_purch         0.1720   0.0661   2.6016 0.0093  0.0424  0.3017\n",
      "FRE              -0.0139   0.0009 -16.2041 0.0000 -0.0156 -0.0123\n",
      "#nouns           -0.7787   0.2001  -3.8919 0.0001 -1.1709 -0.3866\n",
      "#adj             -1.7907   0.2315  -7.7353 0.0000 -2.2444 -1.3370\n",
      "#adv             -1.5662   0.2908  -5.3852 0.0000 -2.1363 -0.9962\n",
      "subjective_score  0.2334   0.0918   2.5437 0.0110  0.0536  0.4132\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.398523\n",
      "         Iterations 7\n",
      "                         Results: Logit\n",
      "=================================================================\n",
      "Model:              Logit            Method:           MLE       \n",
      "Dependent Variable: helpful          Pseudo R-squared: 0.120     \n",
      "Date:               2024-05-28 19:00 AIC:              17729.1944\n",
      "No. Observations:   22211            BIC:              17833.3029\n",
      "Df Model:           12               Log-Likelihood:   -8851.6   \n",
      "Df Residuals:       22198            LL-Null:          -10057.   \n",
      "Converged:          1.0000           LLR p-value:      0.0000    \n",
      "No. Iterations:     7.0000           Scale:            1.0000    \n",
      "-----------------------------------------------------------------\n",
      "                  Coef.  Std.Err.    z     P>|z|   [0.025  0.975]\n",
      "-----------------------------------------------------------------\n",
      "rating           -0.2943   0.0131 -22.4353 0.0000 -0.3200 -0.2686\n",
      "word_count        0.0050   0.0014   3.6845 0.0002  0.0024  0.0077\n",
      "sent_count        0.1845   0.0197   9.3535 0.0000  0.1458  0.2231\n",
      "sent_length       0.0146   0.0030   4.9402 0.0000  0.0088  0.0204\n",
      "title_length     -0.0599   0.0117  -5.1270 0.0000 -0.0828 -0.0370\n",
      "elap_days         0.0001   0.0000   4.1906 0.0000  0.0000  0.0001\n",
      "image             0.8000   0.0823   9.7217 0.0000  0.6387  0.9613\n",
      "ver_purch         0.1663   0.0659   2.5224 0.0117  0.0371  0.2955\n",
      "FRE              -0.0140   0.0009 -16.3475 0.0000 -0.0157 -0.0123\n",
      "#nouns           -0.7840   0.1999  -3.9221 0.0001 -1.1757 -0.3922\n",
      "#adj             -1.7802   0.2313  -7.6969 0.0000 -2.2335 -1.3269\n",
      "#adv             -1.5826   0.2906  -5.4456 0.0000 -2.1522 -1.0130\n",
      "subjective_score  0.2456   0.0913   2.6900 0.0071  0.0667  0.4246\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Deleting Sentiment Classification due not significant\n",
    "numerical_features = ['rating', 'word_count', 'sent_count', 'sent_length', 'title_length', 'elap_days', 'image', 'ver_purch', 'FRE', '#nouns', '#adj', '#adv', 'subjective_score']\n",
    "target = 'helpful'\n",
    "\n",
    "# Concatenate numerical features and dummy variables\n",
    "#X = pd.concat([df[numerical_features], product_dummies], axis=1)\n",
    "X = df [numerical_features]\n",
    "y = df[target]\n",
    "\n",
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# Split data for test and training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[numerical_features],  \n",
    "    df[target], \n",
    "    test_size=0.2,  \n",
    "    random_state=42  # Set a random seed for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>sent_length</th>\n",
       "      <th>title_length</th>\n",
       "      <th>elap_days</th>\n",
       "      <th>image</th>\n",
       "      <th>ver_purch</th>\n",
       "      <th>FRE</th>\n",
       "      <th>#nouns</th>\n",
       "      <th>#adj</th>\n",
       "      <th>#adv</th>\n",
       "      <th>subjective_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.535690</td>\n",
       "      <td>-0.171701</td>\n",
       "      <td>0.269534</td>\n",
       "      <td>-0.520649</td>\n",
       "      <td>-0.315217</td>\n",
       "      <td>2.076454</td>\n",
       "      <td>-0.194396</td>\n",
       "      <td>0.278743</td>\n",
       "      <td>1.097237</td>\n",
       "      <td>-0.796140</td>\n",
       "      <td>-0.639321</td>\n",
       "      <td>-0.249450</td>\n",
       "      <td>0.713360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.255050</td>\n",
       "      <td>-0.615166</td>\n",
       "      <td>-0.649940</td>\n",
       "      <td>-1.034781</td>\n",
       "      <td>-0.315217</td>\n",
       "      <td>0.013387</td>\n",
       "      <td>-0.194396</td>\n",
       "      <td>0.278743</td>\n",
       "      <td>-1.351391</td>\n",
       "      <td>1.230839</td>\n",
       "      <td>4.979213</td>\n",
       "      <td>-0.869362</td>\n",
       "      <td>0.720624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.535690</td>\n",
       "      <td>-0.276046</td>\n",
       "      <td>-0.190203</td>\n",
       "      <td>-0.322906</td>\n",
       "      <td>-0.315217</td>\n",
       "      <td>0.394687</td>\n",
       "      <td>-0.194396</td>\n",
       "      <td>0.278743</td>\n",
       "      <td>-1.174777</td>\n",
       "      <td>-1.664845</td>\n",
       "      <td>-0.525432</td>\n",
       "      <td>1.455309</td>\n",
       "      <td>-0.016021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.255050</td>\n",
       "      <td>0.271764</td>\n",
       "      <td>-0.190203</td>\n",
       "      <td>0.922876</td>\n",
       "      <td>-0.315217</td>\n",
       "      <td>0.567231</td>\n",
       "      <td>-0.194396</td>\n",
       "      <td>0.278743</td>\n",
       "      <td>0.032865</td>\n",
       "      <td>-0.490919</td>\n",
       "      <td>-0.602384</td>\n",
       "      <td>0.135901</td>\n",
       "      <td>0.054558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.535690</td>\n",
       "      <td>-0.458649</td>\n",
       "      <td>-0.649940</td>\n",
       "      <td>-0.085614</td>\n",
       "      <td>-0.315217</td>\n",
       "      <td>0.508651</td>\n",
       "      <td>-0.194396</td>\n",
       "      <td>0.278743</td>\n",
       "      <td>0.094342</td>\n",
       "      <td>-0.699617</td>\n",
       "      <td>0.929819</td>\n",
       "      <td>-0.869362</td>\n",
       "      <td>-0.034329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17763</th>\n",
       "      <td>-2.627272</td>\n",
       "      <td>-0.458649</td>\n",
       "      <td>-0.190203</td>\n",
       "      <td>-0.738166</td>\n",
       "      <td>-0.315217</td>\n",
       "      <td>1.491723</td>\n",
       "      <td>-0.194396</td>\n",
       "      <td>0.278743</td>\n",
       "      <td>0.773185</td>\n",
       "      <td>-0.699617</td>\n",
       "      <td>0.929819</td>\n",
       "      <td>0.508221</td>\n",
       "      <td>-0.663855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17764</th>\n",
       "      <td>0.535690</td>\n",
       "      <td>-0.458649</td>\n",
       "      <td>-0.649940</td>\n",
       "      <td>-0.085614</td>\n",
       "      <td>-0.315217</td>\n",
       "      <td>0.110310</td>\n",
       "      <td>-0.194396</td>\n",
       "      <td>0.278743</td>\n",
       "      <td>0.094342</td>\n",
       "      <td>0.265611</td>\n",
       "      <td>-1.094878</td>\n",
       "      <td>0.508221</td>\n",
       "      <td>-2.264112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17765</th>\n",
       "      <td>0.535690</td>\n",
       "      <td>-0.354304</td>\n",
       "      <td>-0.190203</td>\n",
       "      <td>-0.500875</td>\n",
       "      <td>-0.315217</td>\n",
       "      <td>1.405451</td>\n",
       "      <td>-0.194396</td>\n",
       "      <td>0.278743</td>\n",
       "      <td>0.323575</td>\n",
       "      <td>-0.996610</td>\n",
       "      <td>0.306836</td>\n",
       "      <td>1.038060</td>\n",
       "      <td>0.620752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17766</th>\n",
       "      <td>0.535690</td>\n",
       "      <td>-0.197787</td>\n",
       "      <td>0.729272</td>\n",
       "      <td>-0.708505</td>\n",
       "      <td>-0.315217</td>\n",
       "      <td>-0.397735</td>\n",
       "      <td>-0.194396</td>\n",
       "      <td>0.278743</td>\n",
       "      <td>0.237091</td>\n",
       "      <td>0.621222</td>\n",
       "      <td>1.302790</td>\n",
       "      <td>-0.869362</td>\n",
       "      <td>0.383323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17767</th>\n",
       "      <td>-2.627272</td>\n",
       "      <td>-0.067356</td>\n",
       "      <td>-0.649940</td>\n",
       "      <td>1.812720</td>\n",
       "      <td>-0.315217</td>\n",
       "      <td>1.564149</td>\n",
       "      <td>-0.194396</td>\n",
       "      <td>0.278743</td>\n",
       "      <td>-2.461610</td>\n",
       "      <td>1.230839</td>\n",
       "      <td>0.044014</td>\n",
       "      <td>-0.352768</td>\n",
       "      <td>0.144791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17768 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating  word_count  sent_count  sent_length  title_length  elap_days  \\\n",
       "0      0.535690   -0.171701    0.269534    -0.520649     -0.315217   2.076454   \n",
       "1     -0.255050   -0.615166   -0.649940    -1.034781     -0.315217   0.013387   \n",
       "2      0.535690   -0.276046   -0.190203    -0.322906     -0.315217   0.394687   \n",
       "3     -0.255050    0.271764   -0.190203     0.922876     -0.315217   0.567231   \n",
       "4      0.535690   -0.458649   -0.649940    -0.085614     -0.315217   0.508651   \n",
       "...         ...         ...         ...          ...           ...        ...   \n",
       "17763 -2.627272   -0.458649   -0.190203    -0.738166     -0.315217   1.491723   \n",
       "17764  0.535690   -0.458649   -0.649940    -0.085614     -0.315217   0.110310   \n",
       "17765  0.535690   -0.354304   -0.190203    -0.500875     -0.315217   1.405451   \n",
       "17766  0.535690   -0.197787    0.729272    -0.708505     -0.315217  -0.397735   \n",
       "17767 -2.627272   -0.067356   -0.649940     1.812720     -0.315217   1.564149   \n",
       "\n",
       "          image  ver_purch       FRE    #nouns      #adj      #adv  \\\n",
       "0     -0.194396   0.278743  1.097237 -0.796140 -0.639321 -0.249450   \n",
       "1     -0.194396   0.278743 -1.351391  1.230839  4.979213 -0.869362   \n",
       "2     -0.194396   0.278743 -1.174777 -1.664845 -0.525432  1.455309   \n",
       "3     -0.194396   0.278743  0.032865 -0.490919 -0.602384  0.135901   \n",
       "4     -0.194396   0.278743  0.094342 -0.699617  0.929819 -0.869362   \n",
       "...         ...        ...       ...       ...       ...       ...   \n",
       "17763 -0.194396   0.278743  0.773185 -0.699617  0.929819  0.508221   \n",
       "17764 -0.194396   0.278743  0.094342  0.265611 -1.094878  0.508221   \n",
       "17765 -0.194396   0.278743  0.323575 -0.996610  0.306836  1.038060   \n",
       "17766 -0.194396   0.278743  0.237091  0.621222  1.302790 -0.869362   \n",
       "17767 -0.194396   0.278743 -2.461610  1.230839  0.044014 -0.352768   \n",
       "\n",
       "       subjective_score  \n",
       "0              0.713360  \n",
       "1              0.720624  \n",
       "2             -0.016021  \n",
       "3              0.054558  \n",
       "4             -0.034329  \n",
       "...                 ...  \n",
       "17763         -0.663855  \n",
       "17764         -2.264112  \n",
       "17765          0.620752  \n",
       "17766          0.383323  \n",
       "17767          0.144791  \n",
       "\n",
       "[17768 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "pd.DataFrame(X_train, columns=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8370470402880936\n",
      "F1 Score: 0.2113289760348584\n",
      "AUC: 0.5551949384035673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91      3690\n",
      "           1       0.59      0.13      0.21       753\n",
      "\n",
      "    accuracy                           0.84      4443\n",
      "   macro avg       0.72      0.56      0.56      4443\n",
      "weighted avg       0.80      0.84      0.79      4443\n",
      "\n",
      "[[3622   68]\n",
      " [ 656   97]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_model = LogisticRegression(solver='lbfgs', max_iter=1000)  # You can adjust max_iter as needed\n",
    "\n",
    "# Train the model\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logreg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_auc_score\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_curve\n\u001b[0;32m----> 3\u001b[0m logit_roc_auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, \u001b[43mlogreg\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test))\n\u001b[1;32m      4\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m roc_curve(y_test, logreg\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:,\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logreg' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.394377\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                helpful   No. Observations:                17768\n",
      "Model:                          Logit   Df Residuals:                    17754\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Tue, 28 May 2024   Pseudo R-squ.:                  0.1280\n",
      "Time:                        19:01:16   Log-Likelihood:                -7007.3\n",
      "converged:                       True   LL-Null:                       -8035.5\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.8133      0.024    -76.761      0.000      -1.860      -1.767\n",
      "x1            -0.3281      0.020    -16.813      0.000      -0.366      -0.290\n",
      "x2             0.0509      0.058      0.880      0.379      -0.063       0.164\n",
      "x3             0.5533      0.049     11.318      0.000       0.458       0.649\n",
      "x4             0.2721      0.031      8.644      0.000       0.210       0.334\n",
      "x5            -0.0636      0.025     -2.595      0.009      -0.112      -0.016\n",
      "x6             0.1103      0.021      5.193      0.000       0.069       0.152\n",
      "x7             0.1640      0.017      9.507      0.000       0.130       0.198\n",
      "x8             0.1475      0.023      6.450      0.000       0.103       0.192\n",
      "x9            -0.0894      0.026     -3.415      0.001      -0.141      -0.038\n",
      "x10            0.0041      0.028      0.148      0.883      -0.050       0.058\n",
      "x11           -0.1425      0.029     -4.933      0.000      -0.199      -0.086\n",
      "x12           -0.0709      0.027     -2.605      0.009      -0.124      -0.018\n",
      "x13            0.1309      0.026      5.123      0.000       0.081       0.181\n",
      "==============================================================================\n",
      "Significant coefficients:\n",
      "const    0.000000e+00\n",
      "x1       1.967242e-63\n",
      "x3       1.073573e-29\n",
      "x4       5.431421e-18\n",
      "x5       9.457545e-03\n",
      "x6       2.071188e-07\n",
      "x7       1.961770e-21\n",
      "x8       1.121144e-10\n",
      "x9       6.368341e-04\n",
      "x11      8.083960e-07\n",
      "x12      9.184505e-03\n",
      "x13      2.999658e-07\n",
      "dtype: float64\n",
      "Accuracy: 0.8370470402880936\n",
      "F1 Score: 0.2113289760348584\n",
      "AUC: 0.7369499418765767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91      3690\n",
      "           1       0.59      0.13      0.21       753\n",
      "\n",
      "    accuracy                           0.84      4443\n",
      "   macro avg       0.72      0.56      0.56      4443\n",
      "weighted avg       0.80      0.84      0.79      4443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "# Adding a constant to the model (intercept term)\n",
    "X_train_const = sm.add_constant(X_train)\n",
    "X_test_const = sm.add_constant(X_test)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logit_model = sm.Logit(y_train, X_train_const)\n",
    "\n",
    "# Train the model\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(result.summary())\n",
    "\n",
    "# Get p-values of coefficients\n",
    "p_values = result.pvalues\n",
    "\n",
    "# Significant coefficients (assuming alpha = 0.05)\n",
    "significant_coefs = p_values[p_values < 0.05]\n",
    "print(\"Significant coefficients:\")\n",
    "print(significant_coefs)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred_prob = result.predict(X_test_const)\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)  # Convert probabilities to binary outcomes\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
