{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/paulahofmann/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing Feature Engineering Functions\n",
    "\n",
    "from Feature_Functions import (\n",
    "    calculate_helpful_ratio,\n",
    "    count_pos_tags,\n",
    "    word_count,\n",
    "    sentence_count,\n",
    "    average_words_per_sentence,\n",
    "    title_length,\n",
    "    calculate_flesch_kincaid,\n",
    "    calculate_review_extremity,\n",
    "    calculate_elapsed_time,\n",
    "    image_check,\n",
    "    extract_timestamp,\n",
    "    feature_building\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Data\n",
    "data_hedonic_total = pd.read_csv ('/Users/paulahofmann/Documents/Coding/Online-Review/DataBase/WithMeta/Meta_senti_hedonic.csv')\n",
    "\n",
    "data_hedonic_total.drop (columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "data_hedonic_total.to_csv ('/Users/paulahofmann/Documents/Coding/Online-Review/DataBase/WithMeta/Meta_senti_hedonic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Building Features \n",
    "\n",
    "Building features for each Product Category and Product, using automatically feature building function from the modul Feature Functions, which adds the necessary 12 Features for Model Training to the function. \n",
    "\n",
    "These are the added features:\n",
    "* Helpful Ratio (HR):\n",
    "Calculates the ratio of helpful votes for each review relative to the total helpful votes across all reviews.\n",
    "* POS Tag Counts:\n",
    "Counts the number of adverbs, adjectives, and nouns in each review text.\n",
    "* Word Count:\n",
    "Calculates the total number of words in each review text.\n",
    "* Sentence Count:\n",
    "Counts the total number of sentences in each review text.\n",
    "* Average Words per Sentence:\n",
    "Calculates the average number of words per sentence in each review text.\n",
    "* Title Length (TL):\n",
    "Counts the number of characters in the title of each review. If the title is empty or consists only of special characters, it sets the length to 1.\n",
    "* Flesch-Kincaid Readability Score:\n",
    "Calculates the Flesch-Kincaid readability score for each review text.\n",
    "* Review Extremity:\n",
    "Calculates the difference between the review rating and the average product rating.\n",
    "* Elapsed Time:\n",
    "Calculates the elapsed time (in days) since each review was posted.\n",
    "* Image Check:\n",
    "Checks whether each review contains images and assigns a binary value (0 for no images, 1 for images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for NaN Values in the text column and deleting them\n",
    "data_hedonic_total = data_hedonic_total.dropna(subset=['text'])\n",
    "data_hedonic_total = data_hedonic_total.dropna(subset=['title_x'])\n",
    "\n",
    "#data_utilitarian_razor = data_utilitarian_razor.dropna(subset=['text'])\n",
    "#data_utilitarian_razor = data_utilitarian_razor.dropna(subset=['title_x'])\n",
    "\n",
    "#data_utilitarian_filter = data_utilitarian_filter.dropna(subset=['text'])\n",
    "#data_utilitarian_filter = data_utilitarian_filter.dropna(subset=['title_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hedonic_total['timestamp'] = pd.to_datetime(data_hedonic_total['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Adding Features to Data Hedonic Parfum\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m feature_building (data_hedonic_total) \n",
      "File \u001b[0;32m~/Documents/Coding/Online-Review/ModelPreperation/Feature_Functions.py:191\u001b[0m, in \u001b[0;36mfeature_building\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeature_building\u001b[39m(df):\n\u001b[1;32m    189\u001b[0m     \u001b[39m# Apply all individual functions to the DataFrame\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     df \u001b[39m=\u001b[39m calculate_helpful_ratio(df)\n\u001b[0;32m--> 191\u001b[0m     df \u001b[39m=\u001b[39m count_pos_tags(df)\n\u001b[1;32m    192\u001b[0m     df \u001b[39m=\u001b[39m word_count(df)\n\u001b[1;32m    193\u001b[0m     df \u001b[39m=\u001b[39m sentence_count(df)\n",
      "File \u001b[0;32m~/Documents/Coding/Online-Review/ModelPreperation/Feature_Functions.py:50\u001b[0m, in \u001b[0;36mcount_pos_tags\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m noun_count, adj_count, adv_count\n\u001b[1;32m     49\u001b[0m \u001b[39m# Apply the function to the 'text' column to calculate POS tag counts\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m df[[\u001b[39m'\u001b[39m\u001b[39mnoun_count\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39madj_count\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39madv_count\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: pd\u001b[39m.\u001b[39;49mSeries(count_pos_tags(x)))\n\u001b[1;32m     52\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/pandas/core/series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4521\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4525\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4526\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4527\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4528\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4529\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4628\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4630\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/pandas/core/apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/pandas/core/apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1077\u001b[0m             values,\n\u001b[1;32m   1078\u001b[0m             f,\n\u001b[1;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1080\u001b[0m         )\n\u001b[1;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Coding/Online-Review/ModelPreperation/Feature_Functions.py:50\u001b[0m, in \u001b[0;36mcount_pos_tags.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m noun_count, adj_count, adv_count\n\u001b[1;32m     49\u001b[0m \u001b[39m# Apply the function to the 'text' column to calculate POS tag counts\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m df[[\u001b[39m'\u001b[39m\u001b[39mnoun_count\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39madj_count\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39madv_count\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: pd\u001b[39m.\u001b[39mSeries(count_pos_tags(x)))\n\u001b[1;32m     52\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/Documents/Coding/Online-Review/ModelPreperation/Feature_Functions.py:31\u001b[0m, in \u001b[0;36mcount_pos_tags.<locals>.count_pos_tags\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcount_pos_tags\u001b[39m(text):\n\u001b[1;32m     30\u001b[0m     \u001b[39m# Process the text with spaCy\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     doc \u001b[39m=\u001b[39m nlp(text)\n\u001b[1;32m     33\u001b[0m     \u001b[39m# Initialize counts\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     noun_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/spacy/language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[1;32m   1048\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1049\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcomponent_cfg\u001b[39m.\u001b[39;49mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1051\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/spacy/pipeline/trainable_pipe.pyx:53\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/spacy/pipeline/transition_parser.pyx:343\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.set_annotations\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/spacy/pipeline/_parser_internals/ner.pyx:275\u001b[0m, in \u001b[0;36mspacy.pipeline._parser_internals.ner.BiluoPushDown.set_annotations\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/spacy/tokens/doc.pyx:811\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.set_ents\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/spacy/tokens/doc.pyx:127\u001b[0m, in \u001b[0;36mspacy.tokens.doc.SetEntsDefault.values\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.8/enum.py:398\u001b[0m, in \u001b[0;36mEnumMeta.__members__\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__len__\u001b[39m(\u001b[39mcls\u001b[39m):\n\u001b[1;32m    396\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_member_names_)\n\u001b[0;32m--> 398\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    399\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__members__\u001b[39m(\u001b[39mcls\u001b[39m):\n\u001b[1;32m    400\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[39m    Returns a mapping of member name->value.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \n\u001b[1;32m    403\u001b[0m \u001b[39m    This mapping lists all enum members, including aliases. Note that this\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[39m    is a read-only view of the internal mapping.\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[39mreturn\u001b[39;00m MappingProxyType(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_member_map_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Adding Features to Data Hedonic Parfum\n",
    "feature_building (data_hedonic_total) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_hedonic_total' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_hedonic_total\u001b[39m=\u001b[39mdata_hedonic_total\u001b[39m.\u001b[39mdrop (columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mUnnamed: 0\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[39m#data_hedonic_total.to_csv('/Users/paulahofmann/Documents/Coding/Online-Review/ModelPreperation/Features_hedonic_total.csv', index=False)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_hedonic_total' is not defined"
     ]
    }
   ],
   "source": [
    "data_hedonic_total=data_hedonic_total.drop (columns=['Unnamed: 0'])\n",
    "#data_hedonic_total.to_csv('/Users/paulahofmann/Documents/Coding/Online-Review/ModelPreperation/Features_hedonic_total.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_hedonic_total' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_hedonic_total\u001b[39m.\u001b[39msummary()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_hedonic_total' is not defined"
     ]
    }
   ],
   "source": [
    "data_hedonic_total.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Features to Data Utilitarian Filter\n",
    "feature_building (data_utilitarian_filter) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_utilitarian_filter.to_csv('/Users/paulahofmann/Documents/Coding/Online-Review/ModelPreperation/Features_utilitarian_filter.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Features to Data Utilitarian Razor\n",
    "feature_building (data_utilitarian_razor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_utilitarian_razor.to_csv('/Users/paulahofmann/Documents/Coding/Online-Review/ModelPreperation/Features_utilitarian_razor.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summarizing all Features in a List\n",
    "\n",
    "input_features = ['rating','rating_number','timestamp', 'sentiment', 'price', 'noun_count', 'adj_count', 'adv_count', 'word_count', \n",
    "                  'sentence_count', 'avg_words_per_sentence', 'title_length', 'F-K_score', 'review_extremity', \n",
    "                  'elapsed_time_days', 'image', 'year','month','day','hour']\n",
    "\n",
    "output_feature = 'helpful_ratio'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
