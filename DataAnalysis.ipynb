{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will have a look at the difference in products between hedonic and utilitarian dirven products. We will see if we can find any patterns in the data from a descriptive level and then move on to a more inferential level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages and Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing packages\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from nltk import bigrams\n",
    "from wordcloud import WordCloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "data_utilitarian_filter = pd.read_csv ('/Users/paulahofmann/Documents/Coding/Online-Review/ModelPreperation/Data_with_Features/Features_utilitarian_filter.csv')\n",
    "\n",
    "data_utilitarian_razor = pd.read_csv ('/Users/paulahofmann/Documents/Coding/Online-Review/ModelPreperation/Data_with_Features/Features_utilitarian_razor.csv')\n",
    "\n",
    "data_utilitarian_mouse = pd.read_csv ('/Users/paulahofmann/Documents/Coding/Online-Review/ModelPreperation/Data_with_Features/Features_utilitarian_mouse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = [data_utilitarian_razor, data_utilitarian_filter, data_utilitarian_mouse]\n",
    "\n",
    "# Iterate over each DataFrame\n",
    "for df in data_frames:\n",
    "    # Check if 'timestamp' column exists in the DataFrame\n",
    "    if 'timestamp' in df.columns:\n",
    "        # Convert 'timestamp' column to datetime format\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reviews_by_year(df, title_suffix=None):\n",
    "    # Extract the year from the timestamp\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "\n",
    "    # Plot the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    df['year'].hist(bins=len(df['year'].unique()), color='blue', alpha=0.5)\n",
    "    if title_suffix:\n",
    "        plt.title(f'Distribution of Reviews by Year - {title_suffix}')\n",
    "    else:\n",
    "        plt.title('Distribution of Reviews by Year')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Number of Reviews')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_avg_rating_by_year(df):\n",
    "    # Extract the year from the timestamp\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "\n",
    "    # Group by year and calculate the average rating\n",
    "    avg_rating_by_year = df.groupby('year')['rating'].mean()\n",
    "\n",
    "    # Plot the line chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(avg_rating_by_year.index, avg_rating_by_year.values, color='blue', marker='o', linestyle='-')\n",
    "    plt.title('Average Rating of Reviews by Year')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Average Rating')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# plot_avg_rating_by_year(your_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for showing the amount on reviews by year\n",
    "\n",
    "def plot_rating_counts_by_year(df):\n",
    "    # Extract the year from the timestamp\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "\n",
    "    # Map ratings to categories (1 and 2 as negative, 3 as neutral, 4 and 5 as positive)\n",
    "    rating_categories = {1: 'Negative', 2: 'Negative', 3: 'Neutral', 4: 'Positive', 5: 'Positive'}\n",
    "    df['rating_category'] = df['rating'].map(rating_categories)\n",
    "\n",
    "    # Group by year and rating category, then count the occurrences\n",
    "    rating_counts_by_year = df.groupby(['year', 'rating_category']).size().unstack(fill_value=0)\n",
    "\n",
    "    # Plot the stacked bar plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    rating_counts_by_year.plot(kind='bar', stacked=True, color=['red', 'grey', 'green'], alpha=0.7)\n",
    "    plt.title('Rating Distribution by Year')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Number of Ratings')\n",
    "    plt.legend(title='Rating Category', loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing sentiment distribution by year\n",
    "\n",
    "def plot_sentiment_by_year(df):\n",
    "    # Extract the year from the timestamp\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "\n",
    "    # Plot the box plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='year', y='sentiment', data=df, palette='Set2')\n",
    "    plt.title('Distribution of Text Sentiment by Year')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Text Sentiment')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_rating_and_sentiment_over_time(data_frame):\n",
    "    # Group the data by timestamp and calculate the average rating for each time period\n",
    "    average_rating_over_time = data_frame.groupby(pd.Grouper(key='timestamp', freq='M'))['rating'].mean()\n",
    "\n",
    "    # Group the data by timestamp and calculate the average sentiment score for each time period\n",
    "    average_sentiment_over_time = data_frame.groupby(pd.Grouper(key='timestamp', freq='M'))['sentiment'].mean()\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plotting average rating over time\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Average Rating', color=color)\n",
    "    ax1.plot(average_rating_over_time.index, average_rating_over_time.values, color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Create a secondary y-axis for sentiment score\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:red'\n",
    "    ax2.set_ylabel('Average Sentiment Score', color=color)\n",
    "    ax2.plot(average_sentiment_over_time.index, average_sentiment_over_time.values, color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.title('Average Rating and Sentiment Over Time')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Basic statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            rating                      timestamp  helpful_vote  \\\n",
      "count  4027.000000                           4027   4027.000000   \n",
      "mean      3.800099  2021-04-29 19:04:14.940043776      1.058108   \n",
      "min       1.000000     2018-09-15 03:30:45.715000      0.000000   \n",
      "25%       2.000000  2020-08-03 23:56:41.974500096      0.000000   \n",
      "50%       5.000000  2021-04-22 21:26:25.137999872      0.000000   \n",
      "75%       5.000000  2022-02-25 06:27:49.151000064      0.000000   \n",
      "max       5.000000     2023-08-30 00:33:14.355000   1725.000000   \n",
      "std       1.560987                            NaN     29.667986   \n",
      "\n",
      "       average_rating  rating_number         price    sentiment  \\\n",
      "count    4.027000e+03         4027.0  4.027000e+03  4027.000000   \n",
      "mean     4.700000e+00        46976.0  4.587000e+01     2.754904   \n",
      "min      4.700000e+00        46976.0  4.587000e+01     0.000000   \n",
      "25%      4.700000e+00        46976.0  4.587000e+01     1.000000   \n",
      "50%      4.700000e+00        46976.0  4.587000e+01     4.000000   \n",
      "75%      4.700000e+00        46976.0  4.587000e+01     4.000000   \n",
      "max      4.700000e+00        46976.0  4.587000e+01     4.000000   \n",
      "std      3.570921e-13            0.0  2.593803e-12     1.604537   \n",
      "\n",
      "       helpful_ratio   noun_count    adj_count  ...  avg_words_per_sentence  \\\n",
      "count    4027.000000  4027.000000  4027.000000  ...             4027.000000   \n",
      "mean        0.000248    12.527936     5.703998  ...               19.431932   \n",
      "min         0.000000     0.000000     0.000000  ...                1.666667   \n",
      "25%         0.000000     3.000000     2.000000  ...               10.666667   \n",
      "50%         0.000000     8.000000     4.000000  ...               16.000000   \n",
      "75%         0.000000    16.000000     7.000000  ...               23.500000   \n",
      "max         0.404835   228.000000    82.000000  ...              439.000000   \n",
      "std         0.006963    16.004483     6.670574  ...               16.504547   \n",
      "\n",
      "       title_length   F-K_score  review_extremity  elapsed_time_days  \\\n",
      "count   4027.000000  801.000000       4027.000000        4027.000000   \n",
      "mean       1.299479   10.846105         -0.899901         851.773529   \n",
      "min        1.000000    1.744820         -3.700000           0.000000   \n",
      "25%        1.000000    7.067027         -2.700000         550.500000   \n",
      "50%        1.000000    8.929911          0.300000         859.000000   \n",
      "75%        1.000000   11.855000          0.300000        1120.500000   \n",
      "max       14.000000  151.547071          0.300000        1809.000000   \n",
      "std        1.368951    8.594633          1.560987         404.303385   \n",
      "\n",
      "             image         year        month          day         hour  \n",
      "count  4027.000000  4027.000000  4027.000000  4027.000000  4027.000000  \n",
      "mean      0.042463  2020.855227     6.171343    15.755153    12.342935  \n",
      "min       0.000000  2018.000000     1.000000     1.000000     0.000000  \n",
      "25%       0.000000  2020.000000     3.000000     8.000000     4.000000  \n",
      "50%       0.000000  2021.000000     6.000000    16.000000    14.000000  \n",
      "75%       0.000000  2022.000000     9.000000    23.000000    19.000000  \n",
      "max       1.000000  2023.000000    12.000000    31.000000    23.000000  \n",
      "std       0.201669     1.155625     3.584886     8.850676     7.738097  \n",
      "\n",
      "[8 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Quick overlook of the data\n",
    "print (data_utilitarian_mouse.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             rating                      timestamp  helpful_vote  \\\n",
      "count  11361.000000                          11361  11361.000000   \n",
      "mean       4.003697  2018-01-14 22:46:49.775851776      2.657072   \n",
      "min        1.000000            2008-11-17 15:54:20      0.000000   \n",
      "25%        3.000000            2016-01-19 16:41:50      0.000000   \n",
      "50%        5.000000  2018-02-28 23:52:48.415000064      0.000000   \n",
      "75%        5.000000  2019-12-28 19:16:04.751000064      0.000000   \n",
      "max        5.000000     2023-08-18 14:03:08.916000   9766.000000   \n",
      "std        1.438708                            NaN    111.486786   \n",
      "\n",
      "          sentiment  average_rating  rating_number         price  \\\n",
      "count  11361.000000    1.136100e+04        11361.0  1.136100e+04   \n",
      "mean       3.034680    4.300000e+00        52307.0  4.099000e+01   \n",
      "min        0.000000    4.300000e+00        52307.0  4.099000e+01   \n",
      "25%        2.000000    4.300000e+00        52307.0  4.099000e+01   \n",
      "50%        4.000000    4.300000e+00        52307.0  4.099000e+01   \n",
      "75%        4.000000    4.300000e+00        52307.0  4.099000e+01   \n",
      "max        4.000000    4.300000e+00        52307.0  4.099000e+01   \n",
      "std        1.522725    6.137583e-13            0.0  6.054091e-12   \n",
      "\n",
      "       helpful_ratio    noun_count     adj_count  ...  avg_words_per_sentence  \\\n",
      "count   11361.000000  11361.000000  11361.000000  ...            11361.000000   \n",
      "mean        0.000088      6.296629      3.669307  ...               12.400617   \n",
      "min         0.000000      0.000000      0.000000  ...                1.000000   \n",
      "25%         0.000000      1.000000      1.000000  ...                7.000000   \n",
      "50%         0.000000      4.000000      2.000000  ...               11.000000   \n",
      "75%         0.000000      8.000000      5.000000  ...               16.000000   \n",
      "max         0.323517    236.000000    103.000000  ...              126.000000   \n",
      "std         0.003693      8.988541      4.465543  ...                8.103983   \n",
      "\n",
      "       title_length   F-K_score  review_extremity  elapsed_time_days  \\\n",
      "count  11361.000000  886.000000      11361.000000       11361.000000   \n",
      "mean       1.355074    7.549758         -0.296303        2041.031423   \n",
      "min        1.000000    2.071573         -3.300000           0.000000   \n",
      "25%        1.000000    5.617118         -1.300000        1328.000000   \n",
      "50%        1.000000    6.954427          0.700000        1996.000000   \n",
      "75%        1.000000    8.803719          0.700000        2767.000000   \n",
      "max       15.000000   42.738772          0.700000        5386.000000   \n",
      "std        1.469695    3.258095          1.438708         969.558753   \n",
      "\n",
      "              image          year         month           day          hour  \n",
      "count  11361.000000  11361.000000  11361.000000  11361.000000  11361.000000  \n",
      "mean       0.011443   2017.556817      6.305167     15.676525     12.856527  \n",
      "min        0.000000   2008.000000      1.000000      1.000000      0.000000  \n",
      "25%        0.000000   2016.000000      4.000000      8.000000      5.000000  \n",
      "50%        0.000000   2018.000000      6.000000     16.000000     15.000000  \n",
      "75%        0.000000   2019.000000      9.000000     23.000000     19.000000  \n",
      "max        1.000000   2023.000000     12.000000     31.000000     23.000000  \n",
      "std        0.106361      2.665698      3.338647      8.855711      7.458595  \n",
      "\n",
      "[8 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print (data_utilitarian_filter.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            rating                      timestamp  helpful_vote    sentiment  \\\n",
      "count  5860.000000                           5860   5860.000000  5860.000000   \n",
      "mean      4.066894  2020-05-19 18:16:19.946729728      0.823038     2.988055   \n",
      "min       1.000000            2015-05-31 22:48:04      0.000000     0.000000   \n",
      "25%       4.000000     2019-02-20 21:19:35.976000      0.000000     2.000000   \n",
      "50%       5.000000  2020-08-09 21:03:06.472499968      0.000000     4.000000   \n",
      "75%       5.000000  2021-11-24 11:51:55.073999872      0.000000     4.000000   \n",
      "max       5.000000     2023-08-24 16:41:33.536000   1081.000000     4.000000   \n",
      "std       1.520962                            NaN     18.160139     1.617934   \n",
      "\n",
      "       average_rating  rating_number         price  helpful_ratio  \\\n",
      "count    5.860000e+03         5860.0  5.860000e+03    5860.000000   \n",
      "mean     4.700000e+00        90203.0  5.399000e+01       0.000171   \n",
      "min      4.700000e+00        90203.0  5.399000e+01       0.000000   \n",
      "25%      4.700000e+00        90203.0  5.399000e+01       0.000000   \n",
      "50%      4.700000e+00        90203.0  5.399000e+01       0.000000   \n",
      "75%      4.700000e+00        90203.0  5.399000e+01       0.000000   \n",
      "max      4.700000e+00        90203.0  5.399000e+01       0.224134   \n",
      "std      4.725512e-13            0.0  4.505225e-12       0.003765   \n",
      "\n",
      "        noun_count    adj_count  ...  avg_words_per_sentence  title_length  \\\n",
      "count  5860.000000  5860.000000  ...             5860.000000   5860.000000   \n",
      "mean      4.785324     2.211433  ...               10.706761      1.476621   \n",
      "min       0.000000     0.000000  ...                1.000000      1.000000   \n",
      "25%       1.000000     1.000000  ...                5.000000      1.000000   \n",
      "50%       2.000000     1.000000  ...                9.000000      1.000000   \n",
      "75%       6.000000     3.000000  ...               14.000000      1.000000   \n",
      "max      90.000000    29.000000  ...              117.000000     13.000000   \n",
      "std       6.761688     2.565777  ...                8.602438      1.621655   \n",
      "\n",
      "        F-K_score  review_extremity  elapsed_time_days        image  \\\n",
      "count  215.000000       5860.000000        5860.000000  5860.000000   \n",
      "mean     9.066354         -0.633106        1191.335666     0.011945   \n",
      "min      2.034319         -3.700000           0.000000     0.000000   \n",
      "25%      6.466392         -0.700000         638.000000     0.000000   \n",
      "50%      8.014922          0.300000        1109.000000     0.000000   \n",
      "75%      9.693483          0.300000        1645.000000     0.000000   \n",
      "max     42.494299          0.300000        3006.000000     1.000000   \n",
      "std      5.001216          1.520962         687.425976     0.108650   \n",
      "\n",
      "              year        month          day         hour  \n",
      "count  5860.000000  5860.000000  5860.000000  5860.000000  \n",
      "mean   2019.890956     6.410239    15.665700    13.420307  \n",
      "min    2015.000000     1.000000     1.000000     0.000000  \n",
      "25%    2019.000000     3.000000     8.000000     5.000000  \n",
      "50%    2020.000000     6.000000    16.000000    16.000000  \n",
      "75%    2021.000000     9.000000    23.000000    19.000000  \n",
      "max    2023.000000    12.000000    31.000000    23.000000  \n",
      "std       1.910317     3.460004     8.772835     7.551471  \n",
      "\n",
      "[8 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print (data_utilitarian_razor.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Helpfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for plotting helpfulness distribution\n",
    "\n",
    "def plot_helpfulness_votes_over_time(data_frame):\n",
    "    # Group by timestamp and calculate the sum of helpfulness votes\n",
    "    votes_by_timestamp = data_frame.groupby('timestamp')['helpful_vote'].sum()\n",
    "\n",
    "    # Filter out timestamps with less than or equal to 1 helpful vote\n",
    "    votes_by_timestamp = votes_by_timestamp[votes_by_timestamp > 1]\n",
    "\n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(votes_by_timestamp.index, votes_by_timestamp, color='blue', alpha=0.5)\n",
    "    plt.title('Helpfulness Votes over Time')\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('Total Helpful Votes')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_hedonic_parfum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m helpful_reviews_count \u001b[39m=\u001b[39m data_hedonic_parfum[data_hedonic_parfum[\u001b[39m'\u001b[39m\u001b[39mhelpful_vote\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNumber of reviews with at least one helpful rating:\u001b[39m\u001b[39m\"\u001b[39m, helpful_reviews_count)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_hedonic_parfum' is not defined"
     ]
    }
   ],
   "source": [
    "helpful_reviews_count = data_hedonic_parfum[data_hedonic_parfum['helpful_vote'] > 0].shape[0]\n",
    "print(\"Number of reviews with at least one helpful rating:\", helpful_reviews_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews with at least one helpful rating: 706\n"
     ]
    }
   ],
   "source": [
    "helpful_reviews_count = data_utilitarian_filter[data_utilitarian_filter['helpful_vote'] > 0].shape[0]\n",
    "print(\"Number of reviews with at least one helpful rating:\", helpful_reviews_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews with at least one helpful rating: 1669\n"
     ]
    }
   ],
   "source": [
    "helpful_reviews_count = data_utilitarian_razor[data_utilitarian_razor['helpful_vote'] > 0].shape[0]\n",
    "print(\"Number of reviews with at least one helpful rating:\", helpful_reviews_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Analysis Wordclouds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Wordclouds\n",
    "\n",
    "def generate_wordcloud_reviews_by_sentiment(df):\n",
    "    # Define rating categories\n",
    "    rating_categories = {1: 'Negative', 2: 'Negative', 3: 'Neutral', 4: 'Positive', 5: 'Positive'}\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "    \n",
    "    # Iterate over each sentiment category\n",
    "    for ax, sentiment in zip(axes.flatten(), ['Negative', 'Neutral', 'Positive']):\n",
    "        # Filter out reviews based on sentiment\n",
    "        reviews = df[df['rating'].map(rating_categories) == sentiment]\n",
    "        \n",
    "        # Drop rows where 'text_cleaned1' column contains NaN values\n",
    "        reviews.dropna(subset=['text_cleaned1'], inplace=True)\n",
    "        \n",
    "        # Concatenate the cleaned text of reviews\n",
    "        text = ' '.join(reviews['text_cleaned1'])\n",
    "\n",
    "        # Generate bigrams from the text\n",
    "        bigram_list = list(bigrams(text.split()))\n",
    "\n",
    "        # Create a WordCloud object with bigrams\n",
    "        wordcloud = WordCloud(width=400, height=200, background_color='white').generate_from_frequencies(dict(bigram_list))\n",
    "\n",
    "        # Plot the WordCloud\n",
    "        ax.imshow(wordcloud, interpolation='bilinear')\n",
    "        ax.set_title(f'Word Cloud of {sentiment} Reviews (Bigrams)')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
