{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model\n",
    "\n",
    "In this notebook we will build a simple multiple regression model which will be used as a baseline model for the comparision with the xGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Packages \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Data with Features \n",
    "data_hedonic = pd.read_csv ('/Users/paulahofmann/Documents/Coding/Online-Review/ModelPreperation/Data_with_Features/Features_hedonic_total.csv')\n",
    "data_utilitarian_razor = pd.read_csv ('/Users/paulahofmann/Documents/Coding/Online-Review/ModelPreperation/Data_with_Features/Features_utilitarian_razor.csv')\n",
    "data_utilitarian_filter = pd.read_csv ('/Users/paulahofmann/Documents/Coding/Online-Review/ModelPreperation/Data_with_Features/Features_utilitarian_filter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B09GWLJPTH' 'B08JHZHWZ3' 'B07D13QGXM' 'B00WXP607C' 'B00SNM5US4'\n",
      " 'B00LMIVLXY' 'B0C5WPD2RN' 'B0BLGN9N39']\n"
     ]
    }
   ],
   "source": [
    "unique_parent_asin = data_hedonic['parent_asin'].unique()\n",
    "print(unique_parent_asin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cuccio Naturale Revitalizing Cuticle Oil - Hydrating Oil For Repaired Cuticles Overnight - Remedy For Damaged Skin And Thin Nails - Paraben Free, Cruelty-Free Formula - Pomegranate And Fig - 0.5 Oz'\n",
      " nan 'Versace Pour Homme Eau de Toilette Spray for Men, 6.7 Ounce'\n",
      " 'Olaplex Hair Perfector No 3 Repairing Treatment'\n",
      " 'HSI PROFESSIONAL Argan Oil Heat Protector |\\xa0Protect up to 450ยบ F from Flat Irons'\n",
      " 'Mario Badescu Facial Spray with Aloe, Herbs and Rose Water for All Skin Types, Face Mist that Hydrates, Rejuvenates & Clarifies'\n",
      " 'Pure Instinct Roll-On - The Original Pheromone Infused Essential Oil Perfume Cologne - Unisex For Men and Women - TSA Ready']\n"
     ]
    }
   ],
   "source": [
    "unique_title = data_hedonic['title_y'].unique()\n",
    "print(unique_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = pd.read_csv('/Users/paulahofmann/Documents/Coding/Online-Review/SelectingData/VideoGames/top_200_products_VideoGames.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ss/4y6dgpw950348n7xdxy73vnm0000gn/T/ipykernel_9431/2532158745.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_rows['price'] = '139'\n"
     ]
    }
   ],
   "source": [
    "# First, filter rows where parent_asin is B08JHZHWZ3\n",
    "filtered_rows = data_hedonic[data_hedonic['parent_asin'] == 'B08JHZHWZ3']\n",
    "\n",
    "# Then, update the title_y column in the filtered rows\n",
    "filtered_rows['price'] = '139'\n",
    "\n",
    "# Update the original DataFrame with the modified rows\n",
    "data_hedonic.update(filtered_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will simply sort all reviews that have at least one helpful Vote\n",
    "data_hedonic_reg = data_hedonic[data_hedonic['helpful_vote'] > 0]\n",
    "#data_utilitarian_razor = data_utilitarian_razor[data_utilitarian_razor['helpful_vote'] > 0]\n",
    "#data_utilitarian_filter = data_utilitarian_filter[data_utilitarian_filter['helpful_vote'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summarizing all Features in a List\n",
    "\n",
    "features = ['rating','rating_number', 'sentiment', 'price', 'noun_count', 'adj_count', 'adv_count', 'word_count', \n",
    "                  'sentence_count', 'avg_words_per_sentence', 'title_length', 'review_extremity', \n",
    "                  'elapsed_time_days', 'image', 'year','month','day','hour']\n",
    "\n",
    "target = 'helpful_ratio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39m# Define and fit the model\u001b[39;00m\n\u001b[1;32m      9\u001b[0m model \u001b[39m=\u001b[39m LinearRegression()\n\u001b[0;32m---> 10\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     12\u001b[0m \u001b[39m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     13\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/linear_model/_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    674\u001b[0m n_jobs_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs\n\u001b[1;32m    676\u001b[0m accept_sparse \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive \u001b[39melse\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 678\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    679\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse, y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    680\u001b[0m )\n\u001b[1;32m    682\u001b[0m has_sw \u001b[39m=\u001b[39m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m has_sw:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    621\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    623\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/utils/validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1142\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1143\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1144\u001b[0m     )\n\u001b[0;32m-> 1146\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1147\u001b[0m     X,\n\u001b[1;32m   1148\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1149\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1150\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1151\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1152\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1153\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1154\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1155\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1156\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1157\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1158\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1159\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1160\u001b[0m )\n\u001b[1;32m   1162\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/utils/validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    952\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    953\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    954\u001b[0m         )\n\u001b[1;32m    956\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 957\u001b[0m         _assert_all_finite(\n\u001b[1;32m    958\u001b[0m             array,\n\u001b[1;32m    959\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    960\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    961\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    964\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    965\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/utils/validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    120\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    123\u001b[0m     X,\n\u001b[1;32m    124\u001b[0m     xp\u001b[39m=\u001b[39;49mxp,\n\u001b[1;32m    125\u001b[0m     allow_nan\u001b[39m=\u001b[39;49mallow_nan,\n\u001b[1;32m    126\u001b[0m     msg_dtype\u001b[39m=\u001b[39;49mmsg_dtype,\n\u001b[1;32m    127\u001b[0m     estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    128\u001b[0m     input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    129\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/utils/validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    155\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    158\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# We will start with the Utilitarian Razor Category\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = data_hedonic_reg[features]\n",
    "y = data_hedonic_reg[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Interpret the results\n",
    "coefficients = pd.DataFrame({'Feature': features, 'Coefficient': model.coef_})\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.8650821016175295e-06\n",
      "                   Feature   Coefficient\n",
      "0                   rating  2.090168e-05\n",
      "1                sentiment -6.824327e-05\n",
      "2                    price -2.545927e-17\n",
      "3               noun_count  5.744303e-05\n",
      "4                adj_count  1.880875e-05\n",
      "5                adv_count -1.307756e-04\n",
      "6               word_count  6.551585e-05\n",
      "7           sentence_count -6.405104e-04\n",
      "8   avg_words_per_sentence -1.293302e-04\n",
      "9             title_length  1.208062e-05\n",
      "10        review_extremity  2.090168e-05\n",
      "11       elapsed_time_days -2.707159e-05\n",
      "12                   image  9.675419e-06\n",
      "13                    year -9.898457e-03\n",
      "14                   month -8.187834e-04\n",
      "15                     day -3.636861e-05\n",
      "16                    hour -1.694119e-06\n"
     ]
    }
   ],
   "source": [
    "# We will go on with the Utilitarian Filter Category\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = data_utilitarian_filter[features]\n",
    "y = data_utilitarian_filter[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Interpret the results\n",
    "coefficients = pd.DataFrame({'Feature': features, 'Coefficient': model.coef_})\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.7594663832951985e-30\n",
      "                   Feature   Coefficient\n",
      "0                   rating -5.402864e-17\n",
      "1                sentiment  1.334924e-17\n",
      "2                    price  1.277461e-16\n",
      "3               noun_count -3.049265e-17\n",
      "4                adj_count  8.461563e-17\n",
      "5                adv_count -1.240006e-17\n",
      "6               word_count  1.036355e-17\n",
      "7           sentence_count -1.530411e-16\n",
      "8   avg_words_per_sentence -3.114621e-17\n",
      "9             title_length  5.382613e-17\n",
      "10        review_extremity -1.344474e-17\n",
      "11       elapsed_time_days  7.112989e-19\n",
      "12                   image  7.950223e-15\n",
      "13                    year  2.351139e-16\n",
      "14                   month -1.393993e-17\n",
      "15                     day -8.494438e-18\n",
      "16                    hour  1.655107e-18\n",
      "17           helpful_ratio  1.000000e+00\n"
     ]
    }
   ],
   "source": [
    "# Moving on with hedonic parfum\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = data_hedonic_parfum[features]\n",
    "y = data_hedonic_parfum[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Interpret the results\n",
    "coefficients = pd.DataFrame({'Feature': features, 'Coefficient': model.coef_})\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: rating\n",
      "Comparison between Hedonic Parfum and Utilitarian Razor:\n",
      "T-statistic: -8.398492142032017, p-value: 5.56318054302687e-17\n",
      "Comparison between Hedonic Parfum and Utilitarian Filter:\n",
      "T-statistic: -8.257683285312142, p-value: 1.6455468436268317e-16\n",
      "Comparison between Utilitarian Razor and Utilitarian Filter:\n",
      "T-statistic: 2.678140175667626, p-value: 0.0074102482858745995\n",
      "\n",
      "Feature: sentiment\n",
      "Comparison between Hedonic Parfum and Utilitarian Razor:\n",
      "T-statistic: 2.667289309799916, p-value: 0.007666684617706823\n",
      "Comparison between Hedonic Parfum and Utilitarian Filter:\n",
      "T-statistic: 2.357923961611818, p-value: 0.0183939204878421\n",
      "Comparison between Utilitarian Razor and Utilitarian Filter:\n",
      "T-statistic: -1.8633908780500135, p-value: 0.06242430312108226\n",
      "\n",
      "Feature: price\n",
      "Comparison between Hedonic Parfum and Utilitarian Razor:\n",
      "T-statistic: -inf, p-value: 0.0\n",
      "Comparison between Hedonic Parfum and Utilitarian Filter:\n",
      "T-statistic: -inf, p-value: 0.0\n",
      "Comparison between Utilitarian Razor and Utilitarian Filter:\n",
      "T-statistic: inf, p-value: 0.0\n",
      "\n",
      "Feature: noun_count\n",
      "Comparison between Hedonic Parfum and Utilitarian Razor:\n",
      "T-statistic: 8.236418092218377, p-value: 2.149685212540804e-16\n",
      "Comparison between Hedonic Parfum and Utilitarian Filter:\n",
      "T-statistic: 3.79716134487434, p-value: 0.00014710669117684163\n",
      "Comparison between Utilitarian Razor and Utilitarian Filter:\n",
      "T-statistic: -11.323938496017284, p-value: 1.271337723861702e-29\n",
      "\n",
      "Feature: adj_count\n",
      "Comparison between Hedonic Parfum and Utilitarian Razor:\n",
      "T-statistic: 9.118637753135863, p-value: 1.0128605557547111e-19\n",
      "Comparison between Hedonic Parfum and Utilitarian Filter:\n",
      "T-statistic: 0.27279918759942334, p-value: 0.7850124279272415\n",
      "Comparison between Utilitarian Razor and Utilitarian Filter:\n",
      "T-statistic: -23.101789182579548, p-value: 2.5936891724952807e-116\n",
      "\n",
      "Feature: adv_count\n",
      "Comparison between Hedonic Parfum and Utilitarian Razor:\n",
      "T-statistic: 15.432937269878712, p-value: 9.56218915351678e-53\n",
      "Comparison between Hedonic Parfum and Utilitarian Filter:\n",
      "T-statistic: 4.675763107626812, p-value: 2.9615694271907674e-06\n",
      "Comparison between Utilitarian Razor and Utilitarian Filter:\n",
      "T-statistic: -24.362476992492205, p-value: 6.454951252938774e-129\n",
      "\n",
      "Feature: word_count\n",
      "Comparison between Hedonic Parfum and Utilitarian Razor:\n",
      "T-statistic: 13.456179049790338, p-value: 1.0667709591732849e-40\n",
      "Comparison between Hedonic Parfum and Utilitarian Filter:\n",
      "T-statistic: 5.485636014262448, p-value: 4.20605163041734e-08\n",
      "Comparison between Utilitarian Razor and Utilitarian Filter:\n",
      "T-statistic: -18.575468640117343, p-value: 2.822663319806713e-76\n",
      "\n",
      "Feature: sentence_count\n",
      "Comparison between Hedonic Parfum and Utilitarian Razor:\n",
      "T-statistic: 12.024378376241096, p-value: 6.198021765163884e-33\n",
      "Comparison between Hedonic Parfum and Utilitarian Filter:\n",
      "T-statistic: 4.24081665078728, p-value: 2.2443040485291794e-05\n",
      "Comparison between Utilitarian Razor and Utilitarian Filter:\n",
      "T-statistic: -21.92357422199387, p-value: 4.225688103087057e-105\n",
      "\n",
      "Feature: avg_words_per_sentence\n",
      "Comparison between Hedonic Parfum and Utilitarian Razor:\n",
      "T-statistic: 9.868658552263945, p-value: 8.413334398540714e-23\n",
      "Comparison between Hedonic Parfum and Utilitarian Filter:\n",
      "T-statistic: 7.275569639662336, p-value: 3.671390287987845e-13\n",
      "Comparison between Utilitarian Razor and Utilitarian Filter:\n",
      "T-statistic: -12.724284838898265, p-value: 6.356273988928984e-37\n",
      "\n",
      "Feature: title_length\n",
      "Comparison between Hedonic Parfum and Utilitarian Razor:\n",
      "T-statistic: -1.9899992112098608, p-value: 0.046635384506293294\n",
      "Comparison between Hedonic Parfum and Utilitarian Filter:\n",
      "T-statistic: -0.8574790811426191, p-value: 0.391197841814402\n",
      "Comparison between Utilitarian Razor and Utilitarian Filter:\n",
      "T-statistic: 4.961829109033099, p-value: 7.049867076980107e-07\n",
      "\n",
      "Feature: review_extremity\n",
      "Comparison between Hedonic Parfum and Utilitarian Razor:\n",
      "T-statistic: 0.03665252152823902, p-value: 0.9707632593580475\n",
      "Comparison between Hedonic Parfum and Utilitarian Filter:\n",
      "T-statistic: -3.7534503531518153, p-value: 0.00017526601648967967\n",
      "Comparison between Utilitarian Razor and Utilitarian Filter:\n",
      "T-statistic: -14.27282746790366, p-value: 5.910855673539702e-46\n",
      "\n",
      "Feature: elapsed_time_days\n",
      "Comparison between Hedonic Parfum and Utilitarian Razor:\n",
      "T-statistic: -10.887507722438196, p-value: 2.3506819352337717e-27\n",
      "Comparison between Hedonic Parfum and Utilitarian Filter:\n",
      "T-statistic: -22.143502584569763, p-value: 1.8772397587532323e-106\n",
      "Comparison between Utilitarian Razor and Utilitarian Filter:\n",
      "T-statistic: -59.78234559572903, p-value: 0.0\n",
      "\n",
      "Feature: image\n",
      "Comparison between Hedonic Parfum and Utilitarian Razor:\n",
      "T-statistic: 3.0483227345665656, p-value: 0.0023110403431964386\n",
      "Comparison between Hedonic Parfum and Utilitarian Filter:\n",
      "T-statistic: 3.272768433153876, p-value: 0.0010681040184264596\n",
      "Comparison between Utilitarian Razor and Utilitarian Filter:\n",
      "T-statistic: 0.2917400997407272, p-value: 0.7704888615472574\n",
      "\n",
      "Feature: year\n",
      "Comparison between Hedonic Parfum and Utilitarian Razor:\n",
      "T-statistic: 10.48690020993157, p-value: 1.630226261531355e-25\n",
      "Comparison between Hedonic Parfum and Utilitarian Filter:\n",
      "T-statistic: 21.924413496422467, p-value: 1.95047169406325e-104\n",
      "Comparison between Utilitarian Razor and Utilitarian Filter:\n",
      "T-statistic: 59.5984820317758, p-value: 0.0\n",
      "\n",
      "Feature: month\n",
      "Comparison between Hedonic Parfum and Utilitarian Razor:\n",
      "T-statistic: 2.183766512922799, p-value: 0.029017200367187704\n",
      "Comparison between Hedonic Parfum and Utilitarian Filter:\n",
      "T-statistic: 2.7977685524977773, p-value: 0.005154158332923897\n",
      "Comparison between Utilitarian Razor and Utilitarian Filter:\n",
      "T-statistic: 1.932606503958447, p-value: 0.05330107019114404\n",
      "\n",
      "Feature: day\n",
      "Comparison between Hedonic Parfum and Utilitarian Razor:\n",
      "T-statistic: -0.29666243208879395, p-value: 0.7667342952423488\n",
      "Comparison between Hedonic Parfum and Utilitarian Filter:\n",
      "T-statistic: -0.3169916838065409, p-value: 0.75125560289184\n",
      "Comparison between Utilitarian Razor and Utilitarian Filter:\n",
      "T-statistic: -0.07624740612253905, p-value: 0.9392231536272555\n",
      "\n",
      "Feature: hour\n",
      "Comparison between Hedonic Parfum and Utilitarian Razor:\n",
      "T-statistic: -1.9253309917254113, p-value: 0.05423418819129268\n",
      "Comparison between Hedonic Parfum and Utilitarian Filter:\n",
      "T-statistic: -0.7435749889456502, p-value: 0.45714866143376764\n",
      "Comparison between Utilitarian Razor and Utilitarian Filter:\n",
      "T-statistic: 4.679906236131139, p-value: 2.891909126774816e-06\n",
      "\n",
      "Feature: helpful_ratio\n",
      "Comparison between Hedonic Parfum and Utilitarian Razor:\n",
      "T-statistic: 5.700335857000974, p-value: 1.2514213702623973e-08\n",
      "Comparison between Hedonic Parfum and Utilitarian Filter:\n",
      "T-statistic: 7.681635971600757, p-value: 1.6966100513513194e-14\n",
      "Comparison between Utilitarian Razor and Utilitarian Filter:\n",
      "T-statistic: 1.3818395830979113, p-value: 0.16703888885822787\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ss/4y6dgpw950348n7xdxy73vnm0000gn/T/ipykernel_10756/3139348406.py:19: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  t_stat, p_value = stats.ttest_ind(dataset_1, dataset_2)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Define your features\n",
    "features = ['rating', 'sentiment', 'price', 'noun_count', 'adj_count', 'adv_count', 'word_count', \n",
    "            'sentence_count', 'avg_words_per_sentence', 'title_length', 'review_extremity', \n",
    "            'elapsed_time_days', 'image', 'year', 'month', 'day', 'hour', 'helpful_ratio']\n",
    "\n",
    "# Define your datasets for hedonic and utilitarian products\n",
    "datasets = [data_hedonic_parfum, data_utilitarian_razor, data_utilitarian_filter]\n",
    "product_labels = ['Hedonic Parfum', 'Utilitarian Razor', 'Utilitarian Filter']\n",
    "\n",
    "# Perform statistical testing for each feature\n",
    "for feature in features:\n",
    "    print(f\"Feature: {feature}\")\n",
    "    for i in range(len(datasets)):\n",
    "        for j in range(i+1, len(datasets)):\n",
    "            dataset_1 = datasets[i][feature]\n",
    "            dataset_2 = datasets[j][feature]\n",
    "            t_stat, p_value = stats.ttest_ind(dataset_1, dataset_2)\n",
    "            print(f\"Comparison between {product_labels[i]} and {product_labels[j]}:\")\n",
    "            print(f\"T-statistic: {t_stat}, p-value: {p_value}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
