{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/paulahofmann/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing Feature Engineering Functions from features.functions.py\n",
    "\n",
    "from Feature_Functions import (\n",
    "    calculate_total_helpful_votes,\n",
    "    count_pos_tags,\n",
    "    word_count,\n",
    "    sentence_count,\n",
    "    average_words_per_sentence,\n",
    "    title_length,\n",
    "    calculate_flesch_reading_score,\n",
    "    calculate_review_extremity,\n",
    "    calculate_elapsed_time,\n",
    "    image_check,\n",
    "    extract_timestamp,\n",
    "    verified_purchase,\n",
    "    feature_building\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Importing Data\n",
    "data_hedonic = pd.read_csv ('/Users/paulahofmann/Documents/Coding/Online-Review/FeaturePreperation/Data_with_Features/Final Data/Hedonic_Final_Cleaned.csv')\n",
    "data_utilitarian = pd.read_csv ('/Users/paulahofmann/Documents/Coding/Online-Review/FeaturePreperation/Data_with_Features/Final Data/Utilitarian_Final_Cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_perfume = pd.read_csv ('/Users/paulahofmann/Documents/Coding/Online-Review/FeaturePreperation/Data_with_Features/Final Data/Old Data/Hedonic_Perfume.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hedonic DataFrame columns:\n",
      "['rating', 'title_x', 'text', 'images', 'asin', 'parent_asin', 'user_id', 'timestamp', 'helpful_vote', 'verified_purchase', 'text_cleaned', 'sentiment', 'main_category', 'prod_title', 'average_rating', 'rat_count', 'features', 'price', 'helpful_ratio', 'noun_count', 'adj_count', 'adv_count', 'word_count', 'sent_count', 'sent_length', 'title_length', 'FRE', 'review_ext', 'elap_days', 'image', 'year', 'month', 'day', 'hour', 'product', 'ver_purch', '#nouns', '#adj', '#adv', 'subjective_score', 'neutral_score', 'text_cleaned1']\n"
     ]
    }
   ],
   "source": [
    "print(\"Hedonic DataFrame columns:\")\n",
    "print(data_perfume.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_perfume.drop(['neutral_score'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame with renamed columns:\n",
      "      Rating                                            title_x  \\\n",
      "0        1.0                              Fell prey to the hype   \n",
      "1        5.0  Very clean and pleasant scent. Great value for...   \n",
      "2        2.0                                            It’s ok   \n",
      "3        5.0                   Smells amazing! My new favorite!   \n",
      "4        5.0                                         Five Stars   \n",
      "...      ...                                                ...   \n",
      "8125     5.0                                        Great price   \n",
      "8126     1.0                            The box smelled good...   \n",
      "8127     1.0                            The box smelled good...   \n",
      "8128     5.0                                Great for the price   \n",
      "8129     5.0                                     SMELLS DIVINE!   \n",
      "\n",
      "                                                   text  \\\n",
      "0     I know it's a beloved Fragrance but it's not f...   \n",
      "1     I knew I wasn’t purchasing a high dollar colog...   \n",
      "2                             Not great,  just ok scent   \n",
      "3     The smell is just amazing, this is easily my f...   \n",
      "4                     Smells great what else can I say?   \n",
      "...                                                 ...   \n",
      "8125                                     Smells so good   \n",
      "8126  Lid busted to pieces, cologne everywhere...hop...   \n",
      "8127  Lid busted to pieces, cologne everywhere...hop...   \n",
      "8128                              My boyfriend loves it   \n",
      "8129  Smells delicious!  Found a new one to add to m...   \n",
      "\n",
      "                                                 images        asin  \\\n",
      "0                                                    []  B000P22TIY   \n",
      "1                                                    []  B000P22TIY   \n",
      "2                                                    []  B000P22TIY   \n",
      "3                                                    []  B08F3W312Q   \n",
      "4                                                    []  B000P22TIY   \n",
      "...                                                 ...         ...   \n",
      "8125                                                 []  B000P22TIY   \n",
      "8126  [{'small_image_url': 'https://m.media-amazon.c...  B08F3W312Q   \n",
      "8127  [{'small_image_url': 'https://m.media-amazon.c...  B08F3W312Q   \n",
      "8128                                                 []  B000P22TIY   \n",
      "8129                                                 []  B000P22TIY   \n",
      "\n",
      "     parent_asin                       user_id            timestamp  \\\n",
      "0     B0BJMV1QTR  AEOQGP4XYSEKPXXBWAN4GWAPUO4Q  2022-07-16 03:08:34   \n",
      "1     B0BJMV1QTR  AHQV36LR2CZ2JIXQ472WAC3TCHKQ  2020-12-30 18:49:53   \n",
      "2     B0BJMV1QTR  AHBSL5FBY72KB63INTSP3SNGMFBQ  2023-03-06 16:54:37   \n",
      "3     B0BJMV1QTR  AE7YYSYFEWAYIUCAK4W33CHPP4JQ  2021-01-11 09:55:14   \n",
      "4     B0BJMV1QTR  AGCKNJEV5GRYYAXD7PV32MW7J6JA  2014-10-15 22:29:02   \n",
      "...          ...                           ...                  ...   \n",
      "8125  B0BJMV1QTR  AFYSDN2YELEGJ45YZM4Z4PXZRIBQ  2019-02-19 00:11:36   \n",
      "8126  B0BJMV1QTR  AGECJEQLXR5BEGW3VXVQDID4NWSA  2023-06-27 20:30:56   \n",
      "8127  B0BJMV1QTR  AGECJEQLXR5BEGW3VXVQDID4NWSA  2023-06-27 20:30:56   \n",
      "8128  B0BJMV1QTR  AHIGXX6JORKVB77PHXVYZKDAHQ3A  2019-07-07 21:36:27   \n",
      "8129  B0BJMV1QTR  AHZ6QASQ3R775DOHJENSUQ2T3DRQ  2015-02-16 07:25:51   \n",
      "\n",
      "      helpful_vote  verified_purchase  ... month  day hour       Prod  VerPur  \\\n",
      "0                0               True  ...     7   16    3  Perfume_M       1   \n",
      "1                0               True  ...    12   30   18  Perfume_M       1   \n",
      "2                0               True  ...     3    6   16  Perfume_M       1   \n",
      "3                0              False  ...     1   11    9  Perfume_M       0   \n",
      "4                0               True  ...    10   15   22  Perfume_M       1   \n",
      "...            ...                ...  ...   ...  ...  ...        ...     ...   \n",
      "8125             0               True  ...     2   19    0  Perfume_M       1   \n",
      "8126             0               True  ...     6   27   20  Perfume_M       1   \n",
      "8127             0               True  ...     6   27   20  Perfume_M       1   \n",
      "8128             0              False  ...     7    7   21  Perfume_M       0   \n",
      "8129             0               True  ...     2   16    7  Perfume_M       1   \n",
      "\n",
      "        #nouns      #adj      #adv  Subjective  \\\n",
      "0     0.000000  0.153846  0.000000    0.919004   \n",
      "1     0.179487  0.102564  0.102564    0.809456   \n",
      "2     0.200000  0.400000  0.200000    0.961543   \n",
      "3     0.220779  0.103896  0.090909    0.986344   \n",
      "4     0.000000  0.142857  0.142857    0.892259   \n",
      "...        ...       ...       ...         ...   \n",
      "8125  0.000000  0.333333  0.333333    0.964594   \n",
      "8126  0.230769  0.076923  0.076923    0.873186   \n",
      "8127  0.230769  0.076923  0.076923    0.873186   \n",
      "8128  0.250000  0.000000  0.000000    0.561413   \n",
      "8129  0.181818  0.090909  0.000000    0.950289   \n",
      "\n",
      "                                          text_cleaned1  \n",
      "0                          know beloved fragrance awful  \n",
      "1     know purchase high dollar cologne clean pleasa...  \n",
      "2                                        great ok scent  \n",
      "3     smell amazing easily favorite cologne sadly sc...  \n",
      "4                                           smell great  \n",
      "...                                                 ...  \n",
      "8125                                         smell good  \n",
      "8126              lid bust piece cologne hope well luck  \n",
      "8127              lid bust piece cologne hope well luck  \n",
      "8128                                     boyfriend love  \n",
      "8129           smells delicious find new add collection  \n",
      "\n",
      "[8130 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "# List of tuples with old and new column names\n",
    "column_names = [('rating', 'Rating'), ('sentiment', 'Sentiment'), ('rat_count', 'RatingC'),\n",
    "                ('rat_count', 'RatingC'),('word_count', 'WordC'),('sent_count', 'SentC'),\n",
    "                ('sent_length', 'SentL'),('title_length', 'TitleL'),('review_ext', 'RewExt'),\n",
    "                ('elap_days', 'ElapDays'),('ver_purch', 'VerPur'),('#nous', 'NounR'),\n",
    "                ('#adjs', 'AdjR'),('#advs', 'AdvR'),('subjective_score', 'Subjective'),\n",
    "                ('product', 'Prod'),('image', 'Image')]\n",
    "\n",
    "# Create a dictionary from the list of tuples\n",
    "rename_dict = {old: new for old, new in column_names}\n",
    "\n",
    "# Renaming the columns using the rename method\n",
    "data_perfume.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "# Print the DataFrame with new column names\n",
    "print(\"\\nDataFrame with renamed columns:\")\n",
    "print(data_perfume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_perfume.to_csv('/Users/paulahofmann/Documents/Coding/Online-Review/FeaturePreperation/Data_with_Features/Final Data/Old Data/Hedonic_Perfume.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hedonic['helpful'] = (data_hedonic['helpful_vote'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating the helpful ratio\n",
    "def calculate_total_helpful_votes(df):\n",
    "    for product_id, group in df.groupby('Prod'):\n",
    "        total_helpful_votes = group['helpful_vote'].sum()\n",
    "        df.loc[group.index, 'total_helpful_votes'] = total_helpful_votes\n",
    "        df.loc[group.index, 'helpful_ratio'] = group['helpful_vote'] / total_helpful_votes\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hedonic DataFrame columns:\n",
      "['Rating', 'title_x', 'text', 'images', 'asin', 'parent_asin', 'user_id', 'timestamp', 'helpful_vote', 'Verified_Purchase', 'text_cleaned', 'text_cleaned1', 'Sentiment', 'main_category', 'prod_title', 'average_rating', 'RatingC', 'features', 'price', 'helpful_ratio', 'noun_count', 'adj_count', 'adv_count', 'WordC', 'SentC', 'SentL', 'TitleL', 'FRE', 'RewExt', 'Image', 'year', 'is_weekend', 'Prod', 'VerPur', 'NounR', 'AdjR', 'AdvR', 'Subjective', 'prod_type', 'Sentiment_Classification', 'total_helpful_votes', 'ElapDays']\n",
      "\n",
      "Utilitarian DataFrame columns:\n",
      "['title_x', 'text', 'text_cleaned', 'text_cleaned1', 'images', 'Image', 'helpful_vote', 'total_helpful_votes', 'helpful_ratio', 'RewExt', 'Ratingasin', 'parent_asin', 'main_category', 'prod_title', 'average_rating', 'features', 'price', 'RatingC', 'Prod', 'user_id', 'VerPur', 'verified_purchase', 'timestamp', 'year', 'month', 'day', 'hour', 'ElapDays', 'WordC', 'SentC', 'SentL', 'TitleL', 'noun_count', 'adj_count', 'adv_count', '#nouns', '#adj', '#adv', 'FRE', 'Sentiment', 'Subjective']\n"
     ]
    }
   ],
   "source": [
    "# Print all columns of the renamed DataFrames\n",
    "print(\"Hedonic DataFrame columns:\")\n",
    "print(data_hedonic.columns.tolist())\n",
    "\n",
    "print(\"\\nUtilitarian DataFrame columns:\")\n",
    "print(data_perfume.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['Rating', 'VerPur','Sentiment', 'RatingC', 'WordC', 'SentC', 'SentL', 'TitleL', 'FRE', 'RewExt',\n",
    "                      'ElapDays', 'Image', 'Prod', 'VerPur', 'NounR', 'AdjR', 'AdvR', 'Subjective',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_hedonic.to_csv ('/Users/paulahofmann/Documents/Coding/Online-Review/FeaturePreperation/Data_with_Features/Final Data/Hedonic_Final.csv',index=False)\n",
    "#data_utilitarian.to_csv ('/Users/paulahofmann/Documents/Coding/Online-Review/FeaturePreperation/Data_with_Features/Final Data/Utilitarian_Final.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Building Features \n",
    "\n",
    "Building features for each Product Category and Product, using automatically feature building function from the modul Feature Functions, which adds the necessary 12 Features for Model Training to the function. \n",
    "\n",
    "These are the added features:\n",
    "* Helpful Ratio (HR):\n",
    "Calculates the ratio of helpful votes for each review relative to the total helpful votes across all reviews.\n",
    "* POS Tag Counts:\n",
    "Counts the number of adverbs, adjectives, and nouns in each review text.\n",
    "* Word Count:\n",
    "Calculates the total number of words in each review text.\n",
    "* Sentence Count:\n",
    "Counts the total number of sentences in each review text.\n",
    "* Average Words per Sentence:\n",
    "Calculates the average number of words per sentence in each review text.\n",
    "* Title Length (TL):\n",
    "Counts the number of characters in the title of each review. If the title is empty or consists only of special characters, it sets the length to 1.\n",
    "* Flesch-Kincaid Readability Score:\n",
    "Calculates the Flesch-Kincaid readability score for each review text.\n",
    "* Review Extremity:\n",
    "Calculates the difference between the review rating and the average product rating.\n",
    "* Elapsed Time:\n",
    "Calculates the elapsed time (in days) since each review was posted.\n",
    "* Image Check:\n",
    "Checks whether each review contains images and assigns a binary value (0 for no images, 1 for images).\n",
    "* Verified Purchase:\n",
    "Checks whether the purchase was verified or not.\n",
    "* Day of Week \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for NaN Values in the text + title column and deleting them\n",
    "data_hedonic = data_hedonic.dropna(subset=['text'])\n",
    "data_hedonic = data_hedonic.dropna(subset=['title_x'])\n",
    "\n",
    "# Checking for NaN Values in the text + title column and deleting them\n",
    "data_utilitarian = data_utilitarian.dropna(subset=['text'])\n",
    "data_utilitarian = data_utilitarian.dropna(subset=['title_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the timestamp column into a datetime object\n",
    "data_utilitarian['timestamp'] = pd.to_datetime(data_utilitarian['timestamp'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "data_utilitarian['timestamp'] = data_utilitarian['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Features to Data Utilitarian\n",
    "feature_building (data_utilitarian) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Features to Data Hedonic \n",
    "feature_building (data_hedonic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming adverb,adjective, and noun counts into ratios for better comparability\n",
    "def calculate_ratios(data):\n",
    "    data['NounR'] = data['noun_count'] / data['word_count']\n",
    "    data['AdjR'] = data['adj_count'] / data['word_count']\n",
    "    data['AdvR'] = data['adv_count'] / data['word_count']\n",
    "    return data\n",
    "\n",
    "# Applying the function to the DataFrame\n",
    "calculate_ratios(data_hedonic)\n",
    "calculate_ratios(data_utilitarian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_hedonic.to_csv('/Users/paulahofmann/Documents/Coding/Online-Review/FeaturePreperation/Data_with_Features/Final Data/Hedonic_Final.csv', index=False)\n",
    "#data_utilitarian.to_csv('/Users/paulahofmann/Documents/Coding/Online-Review/FeaturePreperation/Data_with_Features/Final Data/Utilitarian_Final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reording the columns in the DataFrame\n",
    "\n",
    "# Reordered column list\n",
    "reordered_columns = reordered_columns = [\n",
    "    # Review Details\n",
    "    'title_x', 'text', 'text_cleaned', 'text_cleaned1', 'images','Image', 'helpful_vote', 'total_helpful_votes', \n",
    "    'helpful_ratio', 'RewExt','Rating'\n",
    "    \n",
    "    # Product Information\n",
    "    'asin', 'parent_asin', 'main_category', 'prod_title', 'average_rating', 'features', 'price', \n",
    "    'RatingC',  'Prod',\n",
    "    \n",
    "    # User Information\n",
    "    'user_id', 'VerPur', 'verified_purchase',\n",
    "    \n",
    "    # Time Information\n",
    "    'timestamp', 'year', 'month', 'day', 'hour','ElapDays', \n",
    "    \n",
    "    # Text Analysis\n",
    "    'WordC', 'SentC', 'SentL', 'TitleL', 'noun_count', 'adj_count', 'adv_count', \n",
    "    '#nouns', '#adj', '#adv','FRE', 'Sentiment', \"Sentiment_Classification\",'Subjective'\n",
    "]\n",
    "\n",
    "# Apply reindexing to DataFrame\n",
    "data_hedonic = data_hedonic.reindex(columns=reordered_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summarizing all Features in a List\n",
    "\n",
    "input_features = ['rating','rating_number','timestamp', 'sentiment', 'price', 'noun_count', 'adj_count', 'adv_count', 'word_count', \n",
    "                  'sentence_count', 'avg_words_per_sentence', 'title_length', 'F-K_score', 'review_extremity', \n",
    "                  'elapsed_time_days', 'image', 'year','month','day','hour']\n",
    "\n",
    "output_feature = 'helpful_ratio'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Features Summary and Description\n",
    "\n",
    "### 1. rating\n",
    "   - Description: The numerical rating given by the reviewer.\n",
    "   - Type: Continuous\n",
    "\n",
    "### 2. rating_number\n",
    "   - Description: Number of ratings the product has received.\n",
    "   - Type: Continuous\n",
    "\n",
    "### 3. timestamp\n",
    "   - Description: The timestamp of when the review was posted.\n",
    "   - Type: Datetime\n",
    "\n",
    "### 4. sentiment\n",
    "   - Description: Sentiment score of the review text, indicating the positivity or negativity of the sentiment.\n",
    "   - Type: Continuous\n",
    "\n",
    "### 5. price\n",
    "   - Description: Price of the product.\n",
    "   - Type: Continuous\n",
    "\n",
    "### 6. noun_count\n",
    "   - Description: Count of nouns in the review text.\n",
    "   - Type: Integer\n",
    "\n",
    "### 7. adj_count\n",
    "   - Description: Count of adjectives in the review text.\n",
    "   - Type: Integer\n",
    "\n",
    "### 8. adv_count\n",
    "   - Description: Count of adverbs in the review text.\n",
    "   - Type: Integer\n",
    "\n",
    "### 9. word_count\n",
    "   - Description: Total number of words in the review text.\n",
    "   - Type: Integer\n",
    "\n",
    "### 10. sentence_count\n",
    "   - Description: Total number of sentences in the review text.\n",
    "   - Type: Integer\n",
    "\n",
    "### 11. avg_words_per_sentence\n",
    "   - Description: Average number of words per sentence in the review text.\n",
    "   - Type: Continuous\n",
    "\n",
    "### 12. title_length\n",
    "   - Description: Length of the review title in characters.\n",
    "   - Type: Integer\n",
    "\n",
    "### 13. F-K_score\n",
    "   - Description: Flesch-Kincaid readability score of the review text.\n",
    "   - Type: Continuous\n",
    "\n",
    "### 14. review_extremity\n",
    "   - Description: Difference between the review rating and the average product rating.\n",
    "   - Type: Continuous\n",
    "\n",
    "### 15. elapsed_time_days\n",
    "   - Description: Elapsed time (in days) since the review was posted.\n",
    "   - Type: Continuous\n",
    "\n",
    "### 16. image\n",
    "   - Description: Binary variable indicating whether the review contains images.\n",
    "   - Type: Binary (0 or 1)\n",
    "\n",
    "### 17. year\n",
    "   - Description: Year component of the review timestamp.\n",
    "   - Type: Integer\n",
    "\n",
    "### 18. month\n",
    "   - Description: Month component of the review timestamp.\n",
    "   - Type: Integer\n",
    "\n",
    "### 19. day\n",
    "   - Description: Day component of the review timestamp.\n",
    "   - Type: Integer\n",
    "\n",
    "### 20. hour\n",
    "   - Description: Hour component of the review timestamp.\n",
    "   - Type: Integer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
